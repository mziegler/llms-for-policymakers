---
layout: default
title: Prompting strategies
---

# Biases and Equity Concerns

Critical technology researchers have established that AI language models' have major discriminatory biases for race, gender, disability, nationality, and other groups. Since these humongous models are trained on nearly all the text on the open Internet, the models learn to mirror the online societal biases therein. Technologists are researching a variety of ways to mitigate these prejudices and biases, but so far they only partially work.

TODO: add Algorithms of the Opressed example

On top of all this, we also see these models exhibit particular biases in matters of international politics. The models tend to take on the viewpoints of the powerful, economically developed, mostly Western countries as they wrote most of the material that ends up in the models' training data. The perspectives of developing countries and the global south are largely neglected. For example, if you ask ChatGPT if the UK violates human rights, it hems and haws about "it's a complicated issue; it depends on your viewpoint." However if you ask whether Ethiopia violates human rights, ChatGPT quickly and direcly responds that it does indeed violate human rights, and list a number of allegations.

<div class="card">TODO: add examples</div>

Cite this: https://www.state.gov/acpd-official-meeting-minutes-june-14-2023/


More coming on this page!